[
  {
    "objectID": "ref/codes.html",
    "href": "ref/codes.html",
    "title": "Codes",
    "section": "",
    "text": "Contact Info\n\n[street:...]\n[city:...]\n[prov:...]\n[pc:...]\n[country:...]\n[ph:...]\n[cell:...]\n\n[remove phone]\n\nNote that street, city, etc. is only needed for non-Canadian addresses. Canadian addresses, within certain formatting specifications, will be picked up automatically.\nExamples:\n\nsu.extract_address1(\"123 Sesame St, Toronto, ON  M2Z1J9\")\n\n('123 Sesame St', 'Toronto', 'ON', 'M2Z 1J9', 'Canada')\n\n\n\nsu.extract_address1(\n    \"c/o Bob Roberts, 123 Sesame St, Toronto, ON                              M2Z   1J9\"\n)\n\n('c/o Bob Roberts, 123 Sesame St', 'Toronto', 'ON', 'M2Z 1J9', 'Canada')\n\n\n\nsu.extract_address1(\n    \"c/o Bob Roberts, 123 Sesame St,    Toronto   , on             m2z     1J9\"\n)\n\n('c/o Bob Roberts, 123 Sesame St', 'Toronto', 'ON', 'M2Z 1J9', 'Canada')\n\n\nUse commas to separate street, city, and province. Province should be abbreviated.\n\n# error - missing comma\nsu.extract_address1(\"Green Grove, 123 Sesame St,Toronto    on             m2z     1J9\")\n\n2024-12-31 20:13:21.423 | WARNING  | srs_updates.core:extract_address1:441 - Check province - s/b abbreviated; input str: Green Grove, 123 Sesame St,Toronto    on             m2z     1J9\n\n\nCheck province\n\n\n('Green Grove', '123 Sesame St', 'TO', 'M2Z 1J9', 'Canada')\n\n\n\nsu.extract_address1(\n    \"Green Grove, 123 Sesame St,Toronto,    on,             m2z     1J9\"\n)\n\n('Green Grove, 123 Sesame St', 'Toronto', 'ON', 'M2Z 1J9', 'Canada')\n\n\n\n# error - province not abbreviated\nsu.extract_address1(\n    \"Green Grove, 123 Sesame St,Toronto,    Quebec,             m2z     1J9\"\n)\n\n2024-12-31 20:13:21.456 | WARNING  | srs_updates.core:extract_address1:441 - Check province - s/b abbreviated; input str: Green Grove, 123 Sesame St,Toronto,    Quebec,             m2z     1J9\n\n\nCheck province\n\n\n('Green Grove, 123 Sesame St', 'Toronto', 'QU', 'M2Z 1J9', 'Canada')\n\n\nIf there’s other text in front of the address, use // as a separator:\n\nsu.extract_address1(\n    \"some text here // Green Grove Retirement Community, 123 Sesame St,Toronto,    QC,             m2z     1J9\"\n)\n\n('Green Grove Retirement Community, 123 Sesame St',\n 'Toronto',\n 'QC',\n 'M2Z 1J9',\n 'Canada')\n\n\nEmails will also be picked up automatically.\nPhone numbers, if formatted as xxx-xxx-xxxx will also be picked up. Use the [ph:...] code if the format is different (e.g., number has extension). Use [cell:...] to specify cell phone numbers, otherwise it will be picked up as a main/home phone number.\n\n\nDeaths\n\n[mdod:...] or [md:...] - member date of death\n\n[dc] - member proof of death\n\n[sdod:...] or [sd:...] - spouse date of death\n\n[sdc] - spouse proof of death\n\nValues passed into md/sd should preferably be formatted like 1-jan-2020 but any format parseable by the pandas.to_datetime function will work.\n\npd.to_datetime(\"01-jan-2020\")\n\nTimestamp('2020-01-01 00:00:00')\n\n\n\npd.to_datetime(\"1-jan-2020\")\n\nTimestamp('2020-01-01 00:00:00')\n\n\n\npd.to_datetime(\"Jan 1, 2020\")\n\nTimestamp('2020-01-01 00:00:00')\n\n\n\npd.to_datetime(\"Jan. 1, 2020\")\n\nTimestamp('2020-01-01 00:00:00')\n\n\n\npd.to_datetime(\"January 1, 2020\")\n\nTimestamp('2020-01-01 00:00:00')\n\n\n\npd.to_datetime(\"5/17/2020\")\n\nTimestamp('2020-05-17 00:00:00')\n\n\nIt’s best to avoid ambiguous formats like the one above. If there’s ambiguity, the default assumption is the month comes first:\n\npd.to_datetime(\"7/11/2020\")\n\nTimestamp('2020-07-11 00:00:00')\n\n\n\n\nNames\n\n[fn:...] / [ln:...] - member name\n[sfn:...] / [sln:...] - spouse name\n\n\n\nDOB\n\n[mdob:...]\n[sdob:...]\n\n\n\nBanking\n\n[bank:...]\n\nShould be formatted as [bank:xxx-xxxxx-x...]. Simple validation is included to check length of institution/transit numbers.\n\n\nSuspend\n\n[sus] - suspend payments\n\n\n\nMisc\n\n[cls] - flag to close log if default behaviour is to re-assign\n[excl] - indicates the update should be excluded from the maintenance file\n[comment:...] - append to Comment column in address file",
    "crumbs": [
      "ref",
      "Codes"
    ]
  },
  {
    "objectID": "update_xl.html",
    "href": "update_xl.html",
    "title": "08_update_xl",
    "section": "",
    "text": "Module for updating address file. Full package/docs can be found here.\n\n\n00 update\n\n\nmain\n\n main (key_col:str, str_cols:Optional[list[str]]=None,\n       input_file:str='./Book1.xlsx')\n\n…\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nkey_col\nstr\n\nunique id column\n\n\nstr_cols\nOptional\nNone\nAdd all cols where there may be leading zeroes that should be preserved, or if the values should be read in as string.\n\n\ninput_file\nstr\n./Book1.xlsx\nname/path to input file\n\n\nReturns\nNone",
    "crumbs": [
      "08_update_xl"
    ]
  },
  {
    "objectID": "maint_file.html",
    "href": "maint_file.html",
    "title": "04_maint_file",
    "section": "",
    "text": "01 maint file\n\n\ngetPrelimMaintUpdateDF\n\n getPrelimMaintUpdateDF (updates:srs_updates.srs_specific.Updates)\n\nCreate preliminary maintenance file update df from UpdateData objects and address file columns.\n\n\n\n\nType\nDetails\n\n\n\n\nupdates\nUpdates\nss.Updates\n\n\nReturns\nDataFrame\npd.DataFrame\n\n\n\n\n\n\ncleanMaintUpdateDF\n\n cleanMaintUpdateDF (tm:pandas.core.frame.DataFrame)\n\nClean result from getPrelimMaintUpdateDF.\n\n\n\n\nType\nDetails\n\n\n\n\ntm\nDataFrame\npd.DataFrame\n\n\nReturns\nDataFrame\npd.DataFrame",
    "crumbs": [
      "04_maint_file"
    ]
  },
  {
    "objectID": "update_data.html",
    "href": "update_data.html",
    "title": "01_update_data",
    "section": "",
    "text": "Data class to store data associated with various updates (address file, maintenance file, etc).\nUsing a data class here allows for greater flexibility when adding more properties later.\nOther modules in this package extracts/modifies properties/fields to generate files for internal and external data updates.",
    "crumbs": [
      "01_update_data"
    ]
  },
  {
    "objectID": "update_data.html#fields",
    "href": "update_data.html#fields",
    "title": "01_update_data",
    "section": "Fields",
    "text": "Fields\n    note: str = \"\"  # full note incl ID and URL\n\n    # contact info\n    email: str = \"\"\n    phone1: str = \"\"\n    phone2: str = \"\"\n    street: str = \"\"\n    city: str = \"\"\n    prov: str = \"\"\n    pc: str = \"\"\n    country: str = \"\"\n\n    # names\n    mfn: str = \"\"\n    mln: str = \"\"\n    sfn: str = \"\"\n    sln: str = \"\"\n    pin_fn: str = \"\"\n    pin_ln: str = \"\"\n\n    # death\n    mdod_str: str = \"\"\n    mdc: str = \"\"\n    sdod_str: str = \"\"\n    sdc: str = \"\"\n\n    # for Harmony\n    death_note: str = \"\"\n    ticket_num: str = \"\"\n    key: str = \"\"  # from legacy system, before ticket #s were implemented\n\n    # current status\n    cs: str = \"\"\n    csd_str: str = \"\"\n\n    # PIN\n    payee_status: str = \"\"\n    banking: str = \"\"\n\n    # dob\n    mdob_str: str = \"\"\n    sdob_str: str = \"\"\n\n    # PIN\n    srv: bool = False\n    pin_update: bool = False\n    rel_pin_ids: list = field(default_factory=_default_empty_list)\n    pin_group: list = field(default_factory=_default_empty_list)",
    "crumbs": [
      "01_update_data"
    ]
  },
  {
    "objectID": "update_data.html#properties",
    "href": "update_data.html#properties",
    "title": "01_update_data",
    "section": "Properties",
    "text": "Properties\n\n\nUpdateData.ee_id\n\n UpdateData.ee_id ()\n\n-&gt; str - Emp ID #1\n\n\n\nUpdateData.harmony_url\n\n UpdateData.harmony_url ()\n\n-&gt; str - url\n\n\n\nUpdateData.update_date\n\n UpdateData.update_date ()\n\n-&gt; pd.Timestamp - Contact info update date\n\n\n\nUpdateData.full_prov\n\n UpdateData.full_prov ()\n\n-&gt; str - full province name for address file\n\n\n\nUpdateData.bank_inst\n\n UpdateData.bank_inst ()\n\n-&gt; str - inst #\n\n\n\nUpdateData.bank_transit\n\n UpdateData.bank_transit ()\n\n-&gt; str - transit #\n\n\n\nUpdateData.bank_acc\n\n UpdateData.bank_acc ()\n\n-&gt; str - account #\n\n\n\nUpdateData.mdod\n\n UpdateData.mdod ()\n\n-&gt; pd.Timestamp - member DoD\n\n\n\nUpdateData.sdod\n\n UpdateData.sdod ()\n\n-&gt; pd.Timestamp - spouse DoD\n\n\n\nUpdateData.csd\n\n UpdateData.csd ()\n\n-&gt; pd.Timestamp - Date of Current Status\n\n\n\nUpdateData.mdob\n\n UpdateData.mdob ()\n\n-&gt; pd.Timestamp\n\n\n\nUpdateData.sdob\n\n UpdateData.sdob ()\n\n-&gt; pd.Timestamp\n\n\n\nUpdateData.street1\n\n UpdateData.street1 ()\n\n-&gt; str - split if c/o in street or if length exceeds 30 characters\n\n\n\nUpdateData.street2\n\n UpdateData.street2 ()\n\n-&gt; str\n\n\n\nUpdateData.close\n\n UpdateData.close ()\n\n-&gt; str - Flag if the Harmony log should be closed or re-assigned. Y == close, N == re-assign (death case)\n\n\n\nUpdateData.comment\n\n UpdateData.comment ()\n\n-&gt; str - For Comment column in address file",
    "crumbs": [
      "01_update_data"
    ]
  },
  {
    "objectID": "update_data.html#methods",
    "href": "update_data.html#methods",
    "title": "01_update_data",
    "section": "Methods",
    "text": "Methods\n\n\nUpdateData.addNameSuffixIfDeceased\n\n UpdateData.addNameSuffixIfDeceased ()\n\nAdd (Estate of) suffix to first name for deceased member, (died) for deceased spouse\n\n\n\nUpdateData.setSrvFlag\n\n UpdateData.setSrvFlag ()\n\nChecks all associated PIN IDs for a S prefix. Modifies self.srv field if found.",
    "crumbs": [
      "01_update_data"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "00_core",
    "section": "",
    "text": "00 init fxs\n\n\nsetup_logging\n\n setup_logging ()\n\nadd handler attached to updates.log @ trace level and up\n\n\n\nfp\n\n fp (_path:str='', ambiguous_err:bool=True)\n\nFor referencing relative file paths in dev env. Assumes core is always one level down from project root directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\n_path\nstr\n\nstr - eg. \"../dat/some_file.csv\" == \"&lt;project_root&gt;/dat/some_file.csv&gt;\"\n\n\nambiguous_err\nbool\nTrue\nbool - if True, will raise exception if path is ambiguous when running docs generation vs dev env\n\n\nReturns\nstr\n\nstr\n\n\n\n\n\n\ndp\n\n dp (_path:str='', ambiguous_err:bool=True)\n\nFor referencing relative file paths in dev env. Assumes core is always one level down from project root directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\n_path\nstr\n\nstr - eg. \"../dat/some_file.csv\" == \"&lt;project_root&gt;/dat/some_file.csv&gt;\"\n\n\nambiguous_err\nbool\nTrue\nbool - if True, will raise exception if path is ambiguous when running docs generation vs dev env\n\n\nReturns\nstr\n\nstr\n\n\n\n\n\n\nyaml_helper\n\n yaml_helper (fpath:str='./config.yaml', mode:str='r',\n              data:Optional[dict]=None)\n\nHelper function to read, write, append to files in yaml format. Checks for duplicate keys if reading or appending.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfpath\nstr\n./config.yaml\nstr\n\n\nmode\nstr\nr\nstr - r / a / w\n\n\ndata\nOptional\nNone\ncannot be None if writing or appending\n\n\nReturns\ndict\n\ndict - data if reading, {‘r’: 0} if writing/appending\n\n\n\n\n\nCode\n_fp = fp(\"../cfg/cfg.yml\")\nassert os.path.exists(_fp)\nassert list(yaml_helper(_fp).keys()) == [\"test_cml_fp\"]\n\n\n\n\n\n01 email\n\n\nextract_emails\n\n extract_emails (t_str:str)\n\nExtract all emails from note. If multiple emails found, join w/ //…\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\nstr\nemail address\n\n\n\n\n\nCode\nassert extract_emails(\"Some text here bob@gmail.ca some text here\") == \"bob@gmail.ca\"\nassert (\n    extract_emails(\"sdasd asd a232 very.common@example.com //\")\n    == \"very.common@example.com\"\n)\n\nt_str = \"sdasd asd FirstName.LastName@EasierReading.org\"\nassert extract_emails(t_str) == \"FirstName.LastName@EasierReading.org\"\nassert extract_emails(\"sds extract_emails x@example.com asda \") == \"x@example.com\"\nassert (\n    extract_emails(\n        \"long.email-address-with-hyphens@and.subdomains.example.com asda dasd asdasd \"\n    )\n    == \"long.email-address-with-hyphens@and.subdomains.example.com\"\n)\n\nt_str = \"dasd adasd user.name+tag+sorting@example.com asd asd \"\nassert extract_emails(t_str) == \"user.name+tag+sorting@example.com\"\n\nt_str = \"dasd adasd user.name+tag+sorting@s.example    asd asd \"\nassert extract_emails(t_str) == \"user.name+tag+sorting@s.example\"\n\nt_str = (\n    \"dasd bob@gmail.com adasd user.name+tag+sorting@s.example    asd asd \"\n    + \"dasd adasd user.name+tag+sorting@example.com asd asd \"\n)\nassert (\n    extract_emails(t_str)\n    == \"bob@gmail.com // user.name+tag+sorting@s.example // user.name+tag+sorting@example.com\"\n)\n\n\nSupposedly, this is a valid email but the script won’t pick it up. Unlikely to encounter.\n\nt_str = \"admin@exampl sdasd \"\nextract_emails(t_str)\n\n''\n\n\nForward slash is supposedly valid as well but the script won’t pick this up. Unlikely to encounter.\n\nt_str = \"dasd name/surname@example.com sdasd \"\nextract_emails(t_str)\n\n'surname@example.com'\n\n\n\n\n\n02 phone\n\n\nextract_phone1\n\n extract_phone1 (t_str:str)\n\nExtract all phone numbers using xxx-xxx-xxxx pattern or [ph:...] if alternate format (eg. [ph:123-456-7890 ext. 8001])\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\nstr\nstr\n\n\n\n\n\nCode\nassert (\n    extract_phone1(\"dasda  123-123-1234 // 123-343-4521 \")\n    == \"123-123-1234 // 123-343-4521\"\n)\nassert (\n    extract_phone1(\"asdasd as [ph: 903-123-4365 ext 8001] // sadasd \")\n    == \"903-123-4365 ext 8001\"\n)\nassert (\n    extract_phone1(\"asdasd as [pH: 903-123-4365 ext 8001] // sadasd \")\n    == \"903-123-4365 ext 8001\"\n)\n\n\nIf using [ph:...] and there are multiple numbers, put them all within the square brackets.\n\n\nCode\nassert (\n    extract_phone1(\n        \"asdasd as [pH: 903-123-4365 ext 8001] // 123-456-7890 - [cell:999-999-9999] sadasd \"\n    )\n    == \"903-123-4365 ext 8001\"\n)\nassert (\n    extract_phone1(\n        \"asdasd as [pH: 903-123-4365 ext 8001 // 123-456-7890] //  [cell:999-999-9999] sadasd \"\n    )\n    == \"903-123-4365 ext 8001 // 123-456-7890\"\n)\n\n\n\n\n\nextract_phone2\n\n extract_phone2 (t_str:str)\n\nWork or cell - put inside [cell:...]\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\nstr\nstr\n\n\n\n\n\nCode\nassert extract_phone2(\"asdsad 123-213-4521\") == \"\"\nassert extract_phone2(\"asdsad [cell: 123-213-4521  ]\") == \"123-213-4521\"\nassert extract_phone2(\"asdsad [CELL:  123-213-4521  ]\") == \"123-213-4521\"\nassert (\n    extract_phone2(\"asdsad [CELL:  123-213-4521 // 999-99999999999 ]\")\n    == \"123-213-4521 // 999-99999999999\"\n)\n\n\n\n\n\nextract_phone_numbers\n\n extract_phone_numbers (t_str:str)\n\nMain function to extract phone numbers from a note using regex pattern and/or [ph:...] / [cell:...] flags. To remove all phone numbers on file, use [remove phone].\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\ntuple[str, str]\n\n\n\n\nextract_phone_numbers(\".. [remove phone] asdsad\")\n\n('&lt;&lt;&lt;blank&gt;&gt;&gt;', '&lt;&lt;&lt;blank&gt;&gt;&gt;')\n\n\n&lt;&lt;&lt;blank&gt;&gt;&gt; tells the update_xl module / package to clear existing data.\n\nextract_phone_numbers(\"123 sesame st ... 123-345-3245 // [cell: 9051235453]\")\n\n('123-345-3245', '9051235453')\n\n\nMore tests:\n\n\nCode\nassert extract_phone_numbers(\n    \"123 sesame st ... 123-345-3245 // [cell: 905-123-5453]\"\n) == (\"123-345-3245\", \"905-123-5453\")\nassert extract_phone_numbers(\n    \"... [ph: 123-432-5643 ext 900] // [cell: 123-345-4452 ext 9000 ]\"\n) == (\"123-432-5643 ext 900\", \"123-345-4452 ext 9000\")\n\nassert extract_phone_numbers(\"234 123-123-1234 // 234-234-2345\") == (\n    \"123-123-1234 // 234-234-2345\",\n    \"\",\n)\nassert extract_phone_numbers(\n    \"223423434 sadasd 123-123-1234 // 234-234-2345 // [cell: 123-543-9999]\"\n) == (\"123-123-1234 // 234-234-2345\", \"123-543-9999\")\n\nassert extract_phone_numbers(\n    \"223423434 sadasd [ph: 123-123-1234 // 234-234-2345 (POA)]// [cell: 123-543-9999]\"\n) == (\"123-123-1234 // 234-234-2345 (POA)\", \"123-543-9999\")\n\n\n\n\n\n03 address\n\n\nfull_prov_name\n\n full_prov_name (t_str:str)\n\nAddress file uses full name, not abbreviation\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\nstr\nstr\n\n\n\n\n\nCode\nassert full_prov_name(\"FL\") == \"FL\"  # if not found, returns input string\nassert full_prov_name(\"on\") == \"Ontario\"\nassert full_prov_name(\"yt\") == \"Yukon\"\nassert full_prov_name(\"Bc\") == \"British Columbia\"\n\n\n\n\n\nextract_address1\n\n extract_address1 (t_str:str)\n\nFor Canadian addresses.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\ntuple[str, str, str, str, str]: (street, city, abbreviated province, postal code, country)\n\n\n\nAddress can be formatted in a variety of ways. See below tests for examples.\n\n\nCode\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Toronto, ON  M5X 2D1  // ... \"\nassert extract_address1(t_str) == (\n    \"c/o Jim Bob, 123 Sesame St\",\n    \"Toronto\",\n    \"ON\",\n    \"M5X 2D1\",\n    \"Canada\",\n)\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Toronto, ON   M5X2D1  // ... \"\nassert extract_address1(t_str) == (\n    \"c/o Jim Bob, 123 Sesame St\",\n    \"Toronto\",\n    \"ON\",\n    \"M5X 2D1\",\n    \"Canada\",\n)\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Toronto, ON.   M5X2D1  // ... \"\nassert extract_address1(t_str) == (\n    \"c/o Jim Bob, 123 Sesame St\",\n    \"Toronto\",\n    \"ON\",\n    \"M5X 2D1\",\n    \"Canada\",\n)\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Quebec,  QC.   M5X2D1  // ... \"\nassert extract_address1(t_str) == (\n    \"c/o Jim Bob, 123 Sesame St\",\n    \"Quebec\",\n    \"QC\",\n    \"M5X 2D1\",\n    \"Canada\",\n)\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Quebec,  qc.   M5X2D1  // ... \"\nassert extract_address1(t_str) == (\n    \"c/o Jim Bob, 123 Sesame St\",\n    \"Quebec\",\n    \"QC\",\n    \"M5X 2D1\",\n    \"Canada\",\n)\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Some City,  pe,   M5X2D1  // ... \"\nassert extract_address1(t_str) == (\n    \"c/o Jim Bob, 123 Sesame St\",\n    \"Some City\",\n    \"PE\",\n    \"M5X 2D1\",\n    \"Canada\",\n)\n\n\nIf the pattern indicates it is a Canadian address but the province isn’t a valid abbreviation, a warning will be raised:\n\nt_str = \"... // c/o Jim Bob, 123 Sesame St, Some City,  Manitoba,   M5X2D1  // ... \"\nextract_address1(t_str)\n\n2025-02-17 13:47:02.003 | WARNING  | __main__:extract_address1:49 - Check province - s/b abbreviated; input str: ... // c/o Jim Bob, 123 Sesame St, Some City,  Manitoba,   M5X2D1  // ... \n\n\n\n\n\nextract_address2\n\n extract_address2 (t_str:str)\n\nextract_address1 only works for Canadian addresses. This one is for intl addresses.\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\ntuple[str, str, str, str, str]\n\n\n\n\n\nCode\nt_str = \"[street:123 Sesame St][city:Miami][prov:FL][pc:02345][country:US]\"\nassert extract_address2(t_str) == (\"123 Sesame St\", \"Miami\", \"FL\", \"02345\", \"US\")\n\n\n\n\n\n04 names\n\n\nextract_names\n\n extract_names (t_str:str)\n\n[fn:...] / [ln:...] for member. [sfn:...] / [sln:...] for spouse.\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\ntuple[str, str, str, str]\n\n\n\n\n\nCode\nt_str = \"[FN:Bob][Ln: Jim] [sfn:Mary][sln:Thomas]\"\nassert extract_names(t_str) == (\"Bob\", \"Jim\", \"Mary\", \"Thomas\")\n\nt_str = \"[FN:Bob][sfn:Mary][sln:Thomas]\"\nassert extract_names(t_str) == (\"Bob\", \"\", \"Mary\", \"Thomas\")\n\nt_str = \"[fn:  Sam ]\"\nassert extract_names(t_str) == (\"Sam\", \"\", \"\", \"\")\n\n\n\n\n\n05 deaths\n\n\ncheck_mbr_death\n\n check_mbr_death (t_str:str)\n\nChecks for either [mdod:&lt;dod&gt;] or [md:&lt;dod&gt;] in note. &lt;dod&gt; should be a string that can be parsed by the pandas.to_datetime function. Preferably in the format of 1-jan-2020, for example. If there’s proof of death, add [dc] to note.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\ntuple[str, str] - (dod formatted as str, proof of death)\n\n\n\n\nassert check_mbr_death(\" // [mdod:1-jan-2020][dc] // \") == (\n    (\"2020-01-01\"),\n    \"Yes\",\n)\nassert check_mbr_death(\" // [md:1-jan-2020][DC] // \") == (\n    (\"2020-01-01\"),\n    \"Yes\",\n)\nassert check_mbr_death(\" // [md:1-feb-2023] // \") == (\n    (\"2023-02-01\"),\n    \"\",\n)\nassert check_mbr_death(\" // [mdob:1-feb-2023] // \") == (\n    \"\",\n    \"\",\n)\nassert check_mbr_death(\" // [dc] // \") == (\n    \"\",\n    \"Yes\",\n)\n\n\n\n\ncheck_spouse_death\n\n check_spouse_death (t_str:str)\n\nChecks for either [sdod:&lt;dod&gt;] or [sd:&lt;dod&gt;] in note. &lt;dod&gt; should be a string that can be parsed by the pandas.to_datetime function. Preferably in the format of 1-jan-2020, for example. If there’s proof of death, add [sdc] to note.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\ntuple[str,str] - (dod formatted as str, proof of death)\n\n\n\n\n\nCode\nassert check_spouse_death(\" // [sdod:1-jan-2020][sdc] // \") == (\n    (\"2020-01-01\"),\n    \"Yes\",\n)\nassert check_spouse_death(\" // [sd:1-jan-2020][sdc] // \") == (\n    (\"2020-01-01\"),\n    \"Yes\",\n)\nassert check_spouse_death(\" // [sd:1-feb-2023] // \") == (\n    (\"2023-02-01\"),\n    \"\",\n)\nassert check_spouse_death(\" // [sdob:1-feb-2023] // \") == (\n    \"\",\n    \"\",\n)\nassert check_spouse_death(\" // [sdc] // \") == (\n    \"\",\n    \"Yes\",\n)\n\n\n\n\n\nget_cs\n\n get_cs (t_str:str)\n\nGet preliminary current status and date of current status.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\n(current status, curr status date formatted as str)\n\n\n\n\n\nCode\nt_str = \"[sd:1-jan-2023][md:1-feb-2024]\"\nassert get_cs(t_str) == (\"N/A (died)\", (\"2024-02-01\"))\n\nt_str = \"[sd:1-jan-2023][md:1-feb-2024]\"\nassert get_cs(t_str) == (\"N/A (died)\", (\"2024-02-01\"))\n\nt_str = \"[md:1-feb-2024]\"\nassert get_cs(t_str) == (\"N/A (died)\", (\"2024-02-01\"))\n\nt_str = \"[sd:1-feb-2024]\"\nassert get_cs(t_str) == (\"N/A (died)\", (\"2024-02-01\"))\n\n\n\n\n\n06 payee status, banking\n\nDeath of payee == payee status of 04\nIf both death notification and banking received:\n\nMember death notification + banking\n\nno need to add banking to maintenance file\n\nSpouse death notification + banking\n\nPre-deceased spouse: add banking to maintenance file\nSurvivor death: no need to add banking to maintenance file\n\n\n\n\n\npayee_status_and_banking\n\n payee_status_and_banking (t_str:str, validate:bool=True)\n\nGet payee status for PIN: 00 for banking update, 01 for suspend, 04 for payee death. If 00, 2nd element will be new banking info.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nt_str\nstr\n\nstr\n\n\nvalidate\nbool\nTrue\ncheck length of inst / transit numbers\n\n\nReturns\ntuple\n\ntuple[str, str]: (new status code, new banking) // (\"\", \"\") if no change\n\n\n\n\n\nCode\nassert payee_status_and_banking(\"// [bank:123-12334-312312312312] asdasd \") == (\n    \"00\",\n    \"123-12334-312312312312\",\n)\nassert payee_status_and_banking(\"[sus]\") == (\"01\", \"\")\n\nwith pytest.raises(\n    Exception, match=\"Can't suspend payments and update banking info at the same time\"\n):\n    payee_status_and_banking(\"[sus][bank:...]\")\n\nwith pytest.raises(AssertionError, match=\"Invalid transit\"):\n    payee_status_and_banking(\"// [bank:123-132334-312312312312] asdasd \")\nwith pytest.raises(AssertionError, match=\"Invalid institution\"):\n    payee_status_and_banking(\"// [bank:23-13234-312312312312] asdasd \")\n\nassert payee_status_and_banking(\n    \"// [sdod:1-jan-2024][bank:123-12334-312312312312]\"\n) == (\"04\", \"\")\n\nassert payee_status_and_banking(\n    \"// [mdod:1-jan-2024][bank:123-12334-312312312312]\"\n) == (\"04\", \"\")\n\nassert payee_status_and_banking(\"[mdod:1-jan-2020]\") == (\"04\", \"\")\nassert payee_status_and_banking(\"[sdod:1-jan-2020]\") == (\"04\", \"\")\n\nassert payee_status_and_banking(\n    \"// [sdod:1-jan-2020][bank:123-12334-312312312312]\"\n) == (\"04\", \"\")\nassert payee_status_and_banking(\n    \"// [mdod:1-jan-2020][bank:123-12334-312312312312]\"\n) == (\"04\", \"\")\n\n\n\n\n\n07 dob\n\n\ndob_updates\n\n dob_updates (t_str:str)\n\nUpdate DOB in both address file and PIN using the following patterns: [mdob:&lt;dob&gt;], [sdob:&lt;sdob&gt;]\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt_str\nstr\nstr\n\n\nReturns\ntuple\n(mdob formatted as str, sdob formatted as str)\n\n\n\n\n\nCode\nt_str = \"[mdob:1-jan-1960]\"\nassert dob_updates(t_str) == (\"1960-01-01\", \"\")\nt_str = \"[sdob:1-jan-1960]\"\nassert dob_updates(t_str) == (\"\", \"1960-01-01\")\nt_str = \"[mdob:28-feb-1954][sdob:1-jan-1960]\"\nassert dob_updates(t_str) == (\n    \"1954-02-28\",\n    \"1960-01-01\",\n)",
    "crumbs": [
      "00_core"
    ]
  },
  {
    "objectID": "srs_specific.html",
    "href": "srs_specific.html",
    "title": "03_srs_specific",
    "section": "",
    "text": "Class to store and further process UpdateData objects\n\n\n\n\n\n Updates (notes_list:list[str],\n          all_updates:list[srs_updates.update_data.UpdateData]=&lt;factory&gt;,\n          date:str='2025-02-19', rel_pin_ids:list[str]=&lt;factory&gt;,\n          query_df:pandas.core.frame.DataFrame|None=None,\n          test_cml_fp:str|None=None)\n\n\n\n\n    notes_list: list[str]\n    all_updates: list[ud.UpdateData] = field(default_factory=_default_empty_list)\n    date: str = _init_ts()\n    rel_pin_ids: list[str] = field(default_factory=_default_empty_list)\n    query_df: pd.DataFrame = None\n\n\n\n\n\n\n\n Updates.processNotesPrelim ()\n\n*Preliminary processing and conversion of notes into UpdateData objects:\n\nconvert notes into UpdateData objects\nadd first name + suffix if there was a death\ncreate note for re-assigning death-related Harmony logs\nassigns list of UpdateData objects to self.all_updates*\n\n\n\n\n\n\n Updates.filterPinIDs ()\n\nFilter PIN IDs to speed up addAssociatedIDs method. Assigns filtered list to self.rel_pin_ids\n\n\n\n\n\n Updates.addAssociatedIDs ()\n\nFor each UpdateData object, add all associated PIN IDs to ud.rel_pin_ids. E.g., S1234567, X1234567, T1234567, 1234567 would all be associated with a base ID of 1234567.\n\n\n\n\n\n Updates.determineIfSrv ()\n\nCheck if SS in pay\n\n\n\n\n\n Updates.loadQueryDF ()\n\nLoads query tab from CML tracker and assigns to self.query_df\n\n\n\n\n\n Updates.addKeyAndTktNum ()\n\nFor each UpdateData object, check self.query_df for key and ticket number and assign to ud.key and ud.ticket_num\n\n\n\n\n\n Updates.getPinGroup ()\n\nGet payee/PIN group from curr_mbrs sheet for all associated PIN IDs. Append results to ud.pin_group field.\n\n\n\n\n\n Updates.cleanCurrStatus ()\n\nClean current status / date of current status based on UpdateData srv field. Clear Current Status and Date of Current Status if only pre-deceased spouse death reported.\n\n\n\n\n\n Updates.fixPayeeStatus ()\n\nRemove payee status if it’s a spouse death but not SS in PIN.\n\n\n\n\n\n Updates.pinUpdateCheck ()\n\nDetermine which updates s/b included in/excluded from maintenance file\n\n\n\n\n\n\n\n\n Updates.getAFUpdatesDF ()\n\n-&gt; pd.DataFrame - create df for updating address file",
    "crumbs": [
      "03_srs_specific"
    ]
  },
  {
    "objectID": "srs_specific.html#fields",
    "href": "srs_specific.html#fields",
    "title": "03_srs_specific",
    "section": "",
    "text": "notes_list: list[str]\n    all_updates: list[ud.UpdateData] = field(default_factory=_default_empty_list)\n    date: str = _init_ts()\n    rel_pin_ids: list[str] = field(default_factory=_default_empty_list)\n    query_df: pd.DataFrame = None",
    "crumbs": [
      "03_srs_specific"
    ]
  },
  {
    "objectID": "srs_specific.html#methods-post-init",
    "href": "srs_specific.html#methods-post-init",
    "title": "03_srs_specific",
    "section": "",
    "text": "Updates.processNotesPrelim ()\n\n*Preliminary processing and conversion of notes into UpdateData objects:\n\nconvert notes into UpdateData objects\nadd first name + suffix if there was a death\ncreate note for re-assigning death-related Harmony logs\nassigns list of UpdateData objects to self.all_updates*\n\n\n\n\n\n\n Updates.filterPinIDs ()\n\nFilter PIN IDs to speed up addAssociatedIDs method. Assigns filtered list to self.rel_pin_ids\n\n\n\n\n\n Updates.addAssociatedIDs ()\n\nFor each UpdateData object, add all associated PIN IDs to ud.rel_pin_ids. E.g., S1234567, X1234567, T1234567, 1234567 would all be associated with a base ID of 1234567.\n\n\n\n\n\n Updates.determineIfSrv ()\n\nCheck if SS in pay\n\n\n\n\n\n Updates.loadQueryDF ()\n\nLoads query tab from CML tracker and assigns to self.query_df\n\n\n\n\n\n Updates.addKeyAndTktNum ()\n\nFor each UpdateData object, check self.query_df for key and ticket number and assign to ud.key and ud.ticket_num\n\n\n\n\n\n Updates.getPinGroup ()\n\nGet payee/PIN group from curr_mbrs sheet for all associated PIN IDs. Append results to ud.pin_group field.\n\n\n\n\n\n Updates.cleanCurrStatus ()\n\nClean current status / date of current status based on UpdateData srv field. Clear Current Status and Date of Current Status if only pre-deceased spouse death reported.\n\n\n\n\n\n Updates.fixPayeeStatus ()\n\nRemove payee status if it’s a spouse death but not SS in PIN.\n\n\n\n\n\n Updates.pinUpdateCheck ()\n\nDetermine which updates s/b included in/excluded from maintenance file",
    "crumbs": [
      "03_srs_specific"
    ]
  },
  {
    "objectID": "srs_specific.html#methods-public",
    "href": "srs_specific.html#methods-public",
    "title": "03_srs_specific",
    "section": "",
    "text": "Updates.getAFUpdatesDF ()\n\n-&gt; pd.DataFrame - create df for updating address file",
    "crumbs": [
      "03_srs_specific"
    ]
  },
  {
    "objectID": "export.html",
    "href": "export.html",
    "title": "06_export",
    "section": "",
    "text": "00 process notes, export\n\n\nprocess_notes\n\n process_notes (notes:list[str], export:bool=False,\n                test_cml_fp:str|None=None)\n\nProcesses list of notes, converting each one into an UpdateData object and stores them in an Updates container object.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnotes\nlist\n\nlist[str]\n\n\nexport\nbool\nFalse\nIf True, creates export directory w/ datetime suffix and exports the following:- notes list yml- pickled Updates object- AF updates xlsx- working maint file updates xlsx- offcycle file xlsx- log trk xlsx\n\n\ntest_cml_fp\nstr | None\nNone\ndisregard, deprecated\n\n\nReturns\nUpdates\n\nss.Updates",
    "crumbs": [
      "06_export"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "srs_updates",
    "section": "",
    "text": "Docs: https://pyronone.github.io/srs_updates/",
    "crumbs": [
      "srs_updates"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "srs_updates",
    "section": "Overview",
    "text": "Overview\n\nAs I am responsible for the day-to-day data updates for Sears, there can upwards of 100+ tickets assigned to me on on a bi-weekly basis. To make the process less tedious and more efficient, I created several scripts to streamline the process.\nWhat started as relatively simple scripts quickly evolved into full packages designed with maintainability and modularity in mind, along with thorough testing and documentation. This results in:\n\nEasier accommodation for adding new features and/or changing requirements.\nGreater confidence in functionality and higher consistency, reliability, and quality of results.\nEarly detection of potential bugs when refactoring.\nThorough documentation for reference and knowledge sharing purposes.\n\nThis package works in conjunction with some of my other packages to automate/streamline the data update process. Many features can also be used in other plans, especially ones where CIBC Mellon is also the custodian.",
    "crumbs": [
      "srs_updates"
    ]
  },
  {
    "objectID": "index.html#process",
    "href": "index.html#process",
    "title": "srs_updates",
    "section": "Process",
    "text": "Process\n\nScrape tickets: Instead of manually visiting each ticket in the browser, all tickets assigned to me in Harmony are scraped using the Scraper bot from my harmony_automation package.\n\nThe scraper gets all comments/notes from the ticket and cleans/formats them in chronological order.\nTickets where the information is stored in attachments still need to be reviewed manually.\n\nFormat notes: The scraped notes are added to a tracker spreadsheet where they are manually formatted to fit certain patterns/‘codes’.\n\nBy formatting the notes in a particular way, the srs_updates package can automatically extract all the relevant data from the notes to generate files needed for the data updates.\nSee the ref/Codes page for a full list of such ‘codes’.\n\nSteps 1-2 are repeated every couple days until the number of pending updates reaches 100 or so.\n\nRun update: To run an update, a script calls the export.process_notes function to generate all files needed for internal and external data updates. This is typically done every two weeks.\n\nThe address file is updated using the update_xl module, copied over from my update_xl package. A changelog is also generated, showing exactly what was updated and when.\nThe maintenance file is reviewed manually and saved for later. It will later be concatenated with files from subsequent updates and finalized a few days before the monthly deadline.\n\nClose/re-assign tickets: Tickets in Harmony are automatically closed/re-assigned using the main Bot from my harmony_automation package.\n\nThis eliminates the need to manually close/re-assign up to 100+ tickets after each update.",
    "crumbs": [
      "srs_updates"
    ]
  },
  {
    "objectID": "index.html#changelog",
    "href": "index.html#changelog",
    "title": "srs_updates",
    "section": "Changelog",
    "text": "Changelog\n\n1.0.2\n\nUpdate dev environment - minimum Python version is now 3.10\n\n\n\n0.3.3\n\nNo longer need to manually specify if a name update also needs to be added to maintenance file - will be automatically detected.\nNo longer needed to manually specify if a spouse DOD update is a pre-deceased spouse case - will be automatically detected.",
    "crumbs": [
      "srs_updates"
    ]
  }
]